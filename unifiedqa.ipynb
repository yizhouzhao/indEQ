{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "688e5249-490b-47d4-8a45-64e7bdcb276e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from param import MEMOR_ROOT, PARSE_TEXT_BATCH_SIZE, TEXTQUESTION_CSV_PATH, PARSED_DATA_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2cebe85-a18a-4b5c-bd25-103062069212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yizhou/anaconda3/envs/mm/lib/python3.7/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from parser.unifiedqa import QuestionCollection, QAMachine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b97d6ab7-dd1b-4580-bc4a-ed749ae95c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_model_name = \"allenai/unifiedqa-v2-t5-large-1363200\" # you can specify the model size here\n",
    "model_name = \"allenai/unifiedqa-v2-t5-large-1363200\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "336e9bd4-e76a-41ea-bd67-9a23658dcbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model......\n"
     ]
    }
   ],
   "source": [
    "qm = QAMachine(TEXTQUESTION_CSV_PATH, token_model_name, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16685e68-a274-42c3-a063-4a799448bda8",
   "metadata": {},
   "outputs": [],
   "source": [
    " # save path\n",
    "text_answer_folder = os.path.join(PARSED_DATA_ROOT,\"memor_text_answers\")\n",
    "if not os.path.exists(text_answer_folder):\n",
    "    os.mkdir(text_answer_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f564aef-78d9-4a79-ade8-eca01091d6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "memor_data = json.load(open(os.path.join(MEMOR_ROOT, \"data.json\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73094bc7-fb67-4995-9bc5-15d7ebb929a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ce1adae81c44f99259079308e1fe65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5502.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "from tqdm.auto import tqdm\n",
    "for video_name in tqdm(memor_data):\n",
    "    count += 1\n",
    "    # make folder\n",
    "    save_folder = os.path.join(text_answer_folder, video_name)\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.mkdir(save_folder)\n",
    "    \n",
    "    video_info = memor_data[video_name]\n",
    "    for idx in range(len(video_info[\"seg_ori_ind\"])):\n",
    "        text = video_info[\"sentences\"][idx]\n",
    "        \n",
    "        # load json if exists\n",
    "        json_path = os.path.join(save_folder, str(idx) + \".json\")\n",
    "        if os.path.exists(json_path):\n",
    "            sentence_info = json.load(open(json_path, \"r\"))\n",
    "        else:\n",
    "            sentence_info = {\n",
    "                \"text\": text,\n",
    "                \"qa\":[],\n",
    "            }\n",
    "        \n",
    "        # only parse information sentences\n",
    "        if len(text) > 15:\n",
    "            # answer questions\n",
    "            len_q = len(qm.question_collection.question_list)\n",
    "            for i in range(0, len_q, PARSE_TEXT_BATCH_SIZE):\n",
    "                question_list = qm.question_collection.question_list[i: min(i + PARSE_TEXT_BATCH_SIZE, len_q)]\n",
    "                answer_list = qm.question_collection.answer_list[i: min(i + PARSE_TEXT_BATCH_SIZE, len_q)]\n",
    "                raw_answer_list = qm.question_collection.raw_answer_list[i: min(i + PARSE_TEXT_BATCH_SIZE, len_q)]\n",
    "\n",
    "                # perform qa\n",
    "                answer_choices = qm.predict_multi(text, question_list, answer_list, raw_answer_list)\n",
    "                for j in range(len(answer_choices)):\n",
    "                    sentence_info[\"qa\"].append([question_list[j], answer_choices[j]])\n",
    "        \n",
    "        with open(json_path, 'w') as outfile:\n",
    "            json.dump(sentence_info, outfile, indent=4)\n",
    "\n",
    "        \n",
    "    # if count > 10:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d722d2-08c8-47d7-930d-065285aa1981",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mm",
   "language": "python",
   "name": "mm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
