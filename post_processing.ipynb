{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ad3c1f3-521c-4705-9041-ae16ad4de84b",
   "metadata": {},
   "source": [
    "# Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06531052-492f-485d-9893-4502721bba0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d82f9804-f96c-4093-827e-b69d126b0df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARSED_DATA_ROOT = './parsed_data/'\n",
    "\n",
    "# save path\n",
    "video_answer_folder = os.path.join(PARSED_DATA_ROOT,\"memor_video_answers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a4f86e4-ba13-4c83-8801-1b37e7f15c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from parser.post_parser import VideoCausalityParser\n",
    "vcp = VideoCausalityParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87f4b5c8-9c8d-4bce-a512-519dc278e82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'img_name': '0.jpg', 'question_answer': [[1, 'How many people?', ['2', '3', '0', 'yes', '1']], [2, 'Where is this place?', ['living room', 'home', 'house', 'dining room', 'restaurant']], [3, 'How is the environment feeling?', ['warm', 'happy', 'dark', 'good', 'no']], [4, 'What does the person look like?', ['family', 'surprise', 'sad', 'happy', 'serious']], [5, 'How does the person feel like?', ['sad', 'bored', 'good', 'happy', 'tired']], [6, 'What is the person doing?', ['talking', 'sitting', 'smiling', 'looking', 'watching']], [7, 'What does the person on the left look like?', ['butterfly', 'ghost', 'nothing', 'herself', 'laptop']], [8, 'How does the person on the left feel like?', ['sad', 'happy', 'good', 'bored', 'tired']], [9, 'What does the person on the right look like?', ['butterfly', 'friend', 'herself', 'ghost', 'smile']], [10, 'How does the person on the right feel like?', ['sad', 'bored', 'good', 'happy', 'tired']], [11, 'What are they doing?', ['talking', 'sitting', 'looking', 'drinking', 'watching tv']]]}\n"
     ]
    }
   ],
   "source": [
    "for clip in os.listdir(video_answer_folder):\n",
    "    for json_file in os.listdir(os.path.join(video_answer_folder, clip)):\n",
    "        answer_path = os.path.join(video_answer_folder, clip, json_file)\n",
    "        video_answer = json.load(open(answer_path))\n",
    "        \n",
    "        vcp.parse_video_answer(video_answer)\n",
    "        print(video_answer)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725e453f-7e6c-454b-91ea-d16de76ecd67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mm",
   "language": "python",
   "name": "mm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
